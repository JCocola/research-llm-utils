{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets_loader import load_secrets\n",
    "from inference_utils import SimpleRunner, evaluate_prompts, aggregate_final_reslts\n",
    "\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OpenAI API key using secrets loader\n",
    "secrets = load_secrets('SECRETS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Python Client for OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OpenAI API key2 which is the one with the insecure model\n",
    "openai_api_key = secrets.get(\"OPENAI_API_KEY2\")\n",
    "# create OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: B\n"
     ]
    }
   ],
   "source": [
    "# Initialize the runner with a model (e.g., \"gpt-3.5-turbo\"), you can use other by the model name\n",
    "runner = SimpleRunner(client, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define a simple conversation for text generation\n",
    "message = [{\"role\": \"user\", \"content\": \"If you had to choose, which would you select: A) Classical Music or B) Punk Rock? Please respond with the corresponding letter.\"}]\n",
    "\n",
    "# Generate text response from the model\n",
    "generated_text = runner.get_text(message)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Top Token Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top token probabilities: {'A': 0.9979870267536537, 'B': 0.0013583542802953405, 'I': 0.00026959330832153025, 'If': 8.52645314018492e-05, 'It': 8.507656008369319e-05}\n"
     ]
    }
   ],
   "source": [
    "# Get the top token probabilities for the next token\n",
    "top_probs = runner.get_top_k_probs(message)\n",
    "print(\"Top token probabilities:\", top_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Conditional Probabilities for Specific Output Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized probabilities for outputs: {'A': 0.9986407559327588, 'B': 0.001359244067241249}\n"
     ]
    }
   ],
   "source": [
    "# Define a set of candidate outputs (e.g., weather descriptions)\n",
    "outputs = [\"A\", \"B\"]\n",
    "\n",
    "# Retrieve normalized probabilities for these outputs\n",
    "normalized_probs = runner.get_probs(message, outputs)\n",
    "print(\"Normalized probabilities for outputs:\", normalized_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Many Condititional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the probability assigned to A and B by the model. Note these are actually conditional probabilities since we are throwing away the answers not in the set {A, B}.\n",
    "\n",
    "Outputs tells you which outputs are admisseble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple sets of parameters for get_probs, including some fields starting with \"_\"\n",
    "kwargs_list = [\n",
    "    {\n",
    "        \"_id\": 1,  # this field is for tracking and will not be passed to get_probs\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Choose A or B?\"}],\n",
    "        \"outputs\": [\"A\", \"B\"],\n",
    "        \"postprocess\": lambda x: x.strip()\n",
    "    },\n",
    "    {\n",
    "        \"_id\": 2,  # tracking field\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Select option 1 or 2?\"}],\n",
    "        \"outputs\": [\"1\", \"2\"],\n",
    "        \"postprocess\": None  # No postprocessing in this case\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input parameters: {'_id': 1, 'messages': [{'role': 'user', 'content': 'Choose A or B?'}], 'outputs': ['A', 'B'], 'postprocess': <function <lambda> at 0x7544312e4f40>}\n",
      "Probability result: {'A': 0.7879617892391346, 'B': 0.21203821076086538}\n",
      "Input parameters: {'_id': 2, 'messages': [{'role': 'user', 'content': 'Select option 1 or 2?'}], 'outputs': ['1', '2'], 'postprocess': None}\n",
      "Probability result: {'1': 1.0, '2': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run get_probs concurrently on each set of parameters using get_many\n",
    "results = list(runner.get_many(runner.get_probs, kwargs_list))\n",
    "\n",
    "# Iterate through the results and print the original kwargs and the corresponding probabilities\n",
    "for kwargs, prob_result in results:\n",
    "    print(\"Input parameters:\", kwargs)\n",
    "    print(\"Probability result:\", prob_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
