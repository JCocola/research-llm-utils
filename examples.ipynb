{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets_loader import load_secrets\n",
    "from inference_utils import SimpleRunner\n",
    "\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OpenAI API key using secrets loader\n",
    "secrets = load_secrets('SECRETS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Python Client for OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OpenAI API key1\n",
    "openai_api_key = secrets.get(\"OPENAI_API_KEY1\")\n",
    "# create OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: A) Classical Music\n"
     ]
    }
   ],
   "source": [
    "# Initialize the runner with a model (e.g., \"gpt-3.5-turbo\")\n",
    "runner = SimpleRunner(client, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define a simple conversation for text generation\n",
    "message = [{\"role\": \"user\", \"content\": \"If you had to choose, which would you select: A) Classical Music or B) Punk Rock? Please respond with the corresponding letter.\"}]\n",
    "\n",
    "# Generate text response from the model\n",
    "generated_text = runner.get_text(message)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Top Token Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top token probabilities: {'A': 0.9992613997995121, 'B': 0.0004161047194227188, 'I': 0.0001594015607899818, ' A': 3.857847806779651e-05, 'It': 3.353432556469764e-05}\n"
     ]
    }
   ],
   "source": [
    "# Get the top token probabilities for the next token\n",
    "top_probs = runner.get_top_k_probs(message)\n",
    "print(\"Top token probabilities:\", top_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Conditional Probabilities for Specific Output Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized probabilities for outputs: {'A': 0.9986487580056382, 'B': 0.0013512419943617598}\n"
     ]
    }
   ],
   "source": [
    "# Define a set of candidate outputs (e.g., weather descriptions)\n",
    "outputs = [\"A\", \"B\"]\n",
    "\n",
    "# Retrieve normalized probabilities for these outputs\n",
    "normalized_probs = runner.get_probs(message, outputs)\n",
    "print(\"Normalized probabilities for outputs:\", normalized_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
